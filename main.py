import telebot
from telebot import types
from rembg import remove
from PIL import Image, ImageFilter, ImageEnhance, ImageOps, ImageDraw, ImageFont
from io import BytesIO
from stability_sdk import client
import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation
from moviepy.editor import TextClip, CompositeVideoClip, ColorClip, ImageClip
from googletrans import Translator
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­
API_TOKEN = '6665186630:AAEFJwe0PY9P1tfAdq9nBoJtx1YgQb4uiSs'
STABILITY_API_KEY = 'sk-4waRUzV6mGHgE8GXUYeH4EKXlGyLUjBUldrf7E0xpSsZPqPL'
CHANNEL_ID = '@fallt_tec'
OWNER_ID = 588461026  # Ø¶Ø¹ Ù‡Ù†Ø§ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ
USERS_DATA_FILE = "users_data.json"

bot = telebot.TeleBot(API_TOKEN)
bot.set_webhook()
stability_api = client.StabilityInference(key=STABILITY_API_KEY, verbose=True)

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ù…Ù„Ù JSON
def load_users_data():
    try:
        with open(USERS_DATA_FILE, 'r') as file:
            return json.load(file)
    except FileNotFoundError:
        return {}

# Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ Ù…Ù„Ù JSON
def save_users_data(data):
    with open(USERS_DATA_FILE, 'w') as file:
        json.dump(data, file)

# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
def get_users_count():
    users_data = load_users_data()
    return len(users_data)

# Ø¯Ø§Ù„Ø© Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ
def translate_text(text, src_lang='ar', dest_lang='en'):
    translator = Translator()
    translated = translator.translate(text, src=src_lang, dest=dest_lang)
    return translated.text

# Ø¯Ø§Ù„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
def process_image(image_data):
    image = Image.open(BytesIO(image_data))
    output = remove(image)
    return output

# Ø¯Ø§Ù„Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Stable Diffusion
def generate_image(prompt):
    translated_prompt = translate_text(prompt)
    answers = stability_api.generate(prompt=translated_prompt)
    for resp in answers:
        for artifact in resp.artifacts:
            if artifact.finish_reason == generation.FILTER:
                raise Exception("Request triggered the safety filters.")
            if artifact.type == generation.ARTIFACT_IMAGE:
                img = Image.open(BytesIO(artifact.binary))
                return img

# Ø¯Ø§Ù„Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±
def apply_filters(image, options):
    if 'blur' in options:
        image = image.filter(ImageFilter.BLUR)
    if 'contour' in options:
        image = image.filter(ImageFilter.CONTOUR)
    if 'sharpen' in options:
        image = image.filter(ImageFilter.SHARPEN)
    if 'grayscale' in options:
        image = ImageOps.grayscale(image)
    if 'invert' in options:
        image = ImageOps.invert(image)
    if 'enhance_color' in options:
        enhancer = ImageEnhance.Color(image)
        image = enhancer.enhance(2.0)
    if 'enhance_contrast' in options:
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(2.0)
    if 'enhance_brightness' in options:
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(2.0)
    if 'edge_enhance' in options:
        image = image.filter(ImageFilter.EDGE_ENHANCE)
    if 'emboss' in options:
        image = image.filter(ImageFilter.EMBOSS)
    return image

# Ø¯Ø§Ù„Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import TextClip, CompositeVideoClip, ColorClip, ImageClip
import os

def generate_video(description, style='text', background_color='black'):
    try:
        translated_description = translate_text(description)
        clip_duration = 5  # Ø·ÙˆÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
        fps = 24  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ©

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
        background_clip = ColorClip(size=(720, 1280), color=background_color).set_duration(clip_duration)

        if style == 'text':
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pillow
            img = Image.new('RGB', (720, 1280), color=background_color)
            draw = ImageDraw.Draw(img)
            try:
                # ØªØ­Ù…ÙŠÙ„ Ø®Ø· ÙŠØ¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
                font = ImageFont.truetype("arial.ttf", 70)  # Ø§Ø³ØªØ¨Ø¯Ù„ "arial.ttf" Ø¨Ø®Ø· ÙŠØ¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            except IOError:
                font = ImageFont.load_default()  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø· Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø·
            text_width, text_height = draw.textsize(translated_description, font=font)
            text_position = ((img.width - text_width) // 2, (img.height - text_height) // 2)
            draw.text(text_position, translated_description, font=font, fill=(255, 255, 255))

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†ØµÙŠØ©
            text_image_path = "text_image.png"
            img.save(text_image_path)

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†ØµÙŠØ© ÙƒÙ€ ImageClip
            text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position('center')
            video = CompositeVideoClip([background_clip, text_clip])
        elif style == 'animated':
            # Ø¥Ø¶Ø§ÙØ© ØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªØ­Ø±ÙƒØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            text_clip = TextClip(translated_description, fontsize=70, color='white', size=(720, 1280))
            text_clip = text_clip.set_duration(clip_duration).set_position('center')
            video = CompositeVideoClip([background_clip, text_clip])

        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        video_path = "output.mp4"
        video.write_videofile(video_path, codec="libx264", fps=fps)

        # Ø­Ø°Ù Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¨Ø¹Ø¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        if os.path.exists(text_image_path):
            os.remove(text_image_path)

        return video_path
    except Exception as e:
        raise Exception(f"Error generating video: {str(e)}")
# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
@bot.message_handler(content_types=['photo'])
def handle_image(message):
    if not is_subscribed(message.from_user.id):
        bot.reply_to(message, "ğŸ”” **ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø© Ù„ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª.**")
        return

    file_info = bot.get_file(message.photo[-1].file_id)
    downloaded_file = bot.download_file(file_info.file_path)

    # ØªÙ‚Ø¯ÙŠÙ… Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ± Ø¹Ø¨Ø± Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    markup = types.InlineKeyboardMarkup(row_width=2)
    filters = [
        ('Blur', 'blur'),
        ('Contour', 'contour'),
        ('Sharpen', 'sharpen'),
        ('Grayscale', 'grayscale'),
        ('Invert', 'invert'),
        ('Enhance Color', 'enhance_color'),
        ('Enhance Contrast', 'enhance_contrast'),
        ('Enhance Brightness', 'enhance_brightness'),
        ('Edge Enhance', 'edge_enhance'),
        ('Emboss', 'emboss'),
        ('Remove Background', 'remove_bg')  # Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
    ]
    for filter_name, filter_key in filters:
        markup.add(types.InlineKeyboardButton(filter_name, callback_data=filter_key))
    
    bot.reply_to(message, "ğŸ”§ **Ø§Ø®ØªØ± Ø®ÙŠØ§Ø±Ù‹Ø§ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø£Ø¯Ù†Ø§Ù‡ Ù„ØªØ·Ø¨ÙŠÙ‚Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©:**", reply_markup=markup)

# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙÙ„Ø§ØªØ±
@bot.callback_query_handler(func=lambda call: True)
def handle_filter_selection(call):
    filter_option = call.data
    file_info = bot.get_file(call.message.photo[-1].file_id)
    downloaded_file = bot.download_file(file_info.file_path)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
    remove_bg = (filter_option == 'remove_bg')
    image = process_image(downloaded_file, remove_bg)
    
    if filter_option != 'remove_bg':
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ù…Ø­Ø¯Ø¯
        filtered_image = apply_filters(image, [filter_option])

        output_buffer = BytesIO()
        filtered_image.save(output_buffer, format='PNG')
        output_buffer.seek(0)
        
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="âœ… **ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø¨Ù†Ø¬Ø§Ø­!**",
            reply_markup=None
        )
        bot.send_photo(call.message.chat.id, output_buffer)
    else:
        output_buffer = BytesIO()
        image.save(output_buffer, format='PNG')
        output_buffer.seek(0)
        
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="âœ… **ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!**",
            reply_markup=None
        )
        bot.send_photo(call.message.chat.id, output_buffer)

# Ø¯Ø§Ù„Ø© Ù„Ù„ØªØ±Ø­ÙŠØ¨ ÙˆØ¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
@bot.message_handler(commands=['start'])
def send_welcome(message):
    if not is_subscribed(message.from_user.id):
        bot.reply_to(message, "ğŸ”” **ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø© @fallt_tec Ù„ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª/n Ø§Ø°Ø§ Ø§Ø±Ø¯Øª ØªØ¹Ø¯ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ø±Ø³Ù„ Ø§Ù„ØµÙˆØ±Ø© ÙÙ‚Ø· ÙˆØ³ØªØ¸Ù‡Ø± Ù„Ùƒ Ø§Ù„Ø§Ø¹Ø¯Ø§Ø¯Ø§Øª.**")
        return

    markup = types.ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
    item1 = types.KeyboardButton("Ø¹Ø±Ø¶ Ø§Ù„ÙÙ„Ø§ØªØ±")
    item2 = types.KeyboardButton("ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©")
    #item3 = types.KeyboardButton("ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ")
    item4 = types.KeyboardButton("Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")
    markup.add(item1, item2, item4)
    
    bot.reply_to(message, "ğŸ‘‹ **Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ Ø¨ÙˆØª ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØ±.**", reply_markup=markup)

# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø²Ø± "ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©"
@bot.message_handler(func=lambda message: message.text == 'ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©')
def prompt_generate_image(message):
    bot.reply_to(message, "âœï¸ **ÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡.**")

# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø²Ø± "ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ"
''''@bot.message_handler(func=lambda message: message.text == 'ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ')
def prompt_generate_video(message):
    bot.reply_to(message, "ğŸ¥ **ÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡.**")
'''
# Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
@bot.message_handler(func=lambda message: message.text == 'Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©')
def send_help(message):
    help_text = """
    ğŸ“œ **Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
    - **Ø¹Ø±Ø¶ Ø§Ù„ÙÙ„Ø§ØªØ±**: Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…ØªØ§Ø­Ø©.
    - **ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©**: Ø£Ø±Ø³Ù„ ÙˆØµÙÙ‹Ø§ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
    - **ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ**: Ø£Ø±Ø³Ù„ ÙˆØµÙÙ‹Ø§ Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
    - **Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©**: Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª.
    - **Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„Ù…Ø§Ù„Ùƒ**: (Ù…ØªØ§Ø­Ø© ÙÙ‚Ø· Ù„Ù„Ù…Ø§Ù„Ùƒ) Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙˆØª.
    
    **ÙÙ„Ø§ØªØ± Ù…ØªØ§Ø­Ø©:**
    - Blur
    - Contour
    - Sharpen
    - Grayscale
    - Invert
    - Enhance Color
    - Enhance Contrast
    - Enhance Brightness
    - Edge Enhance
    - Emboss

    Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª ØªÙ…Øª Ø¨Ø±Ù…Ø¬ØªÙ‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ @hemonybot.
    """
    bot.reply_to(message, help_text)


# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
@bot.message_handler(func=lambda message: True)
def handle_generate(message):
    prompt = message.text.strip()

    if ";;ÙÙŠØ¯ÙŠÙˆ" in prompt:
        try:
            video = generate_video(prompt.replace('ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ', '').strip())
            with open(video, "rb") as video_file:
                bot.send_video(message.chat.id, video_file)
        except Exception as e:
            bot.reply_to(message, f"âš ï¸ **Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {str(e)}**")
    else:
        try:
            generated_image = generate_image(prompt.replace('ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©', '').strip())
            output_buffer = BytesIO()
            generated_image.save(output_buffer, format='PNG')
            output_buffer.seek(0)
            bot.send_photo(message.chat.id, output_buffer)
        except Exception as e:
            bot.reply_to(message, f"âš ï¸ **Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©: **")

# Ø¯Ø§Ù„Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø©
def is_subscribed(user_id):
    try:
        member = bot.get_chat_member(CHANNEL_ID, user_id)
        return member.status in ['member', 'administrator', 'creator']
    except Exception:
        return False

# Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª
bot.polling()
